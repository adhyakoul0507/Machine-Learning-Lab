{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NocirH9DFyYc",
        "outputId": "bf993f26-a70c-4cc7-d6b0-877cf14ac716"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching: https://books.toscrape.com/\n",
            "Fetching: https://books.toscrape.com/catalogue/page-2.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-3.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-4.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-5.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-6.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-7.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-8.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-9.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-10.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-11.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-12.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-13.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-14.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-15.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-16.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-17.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-18.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-19.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-20.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-21.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-22.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-23.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-24.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-25.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-26.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-27.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-28.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-29.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-30.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-31.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-32.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-33.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-34.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-35.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-36.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-37.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-38.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-39.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-40.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-41.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-42.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-43.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-44.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-45.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-46.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-47.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-48.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-49.html\n",
            "Fetching: https://books.toscrape.com/catalogue/page-50.html\n",
            "Saved 1000 books to books.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "BASE = \"https://books.toscrape.com/\"\n",
        "\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
        "}\n",
        "\n",
        "books = []\n",
        "\n",
        "\n",
        "url = BASE\n",
        "while True:\n",
        "    print(\"Fetching:\", url)\n",
        "    resp = requests.get(url, headers=headers, timeout=15)\n",
        "    resp.raise_for_status()\n",
        "    soup = BeautifulSoup(resp.text, \"lxml\")\n",
        "\n",
        "\n",
        "    for article in soup.select(\"article.product_pod\"):\n",
        "\n",
        "        a = article.select_one(\"h3 a\")\n",
        "        title = a[\"title\"].strip()\n",
        "\n",
        "\n",
        "        price_tag = article.select_one(\"p.price_color\")\n",
        "        price = price_tag.text.strip() if price_tag else \"\"\n",
        "\n",
        "\n",
        "        avail_tag = article.select_one(\"p.instock.availability\")\n",
        "        availability = avail_tag.text.strip() if avail_tag else \"\"\n",
        "\n",
        "\n",
        "        star_tag = article.select_one(\"p.star-rating\")\n",
        "        star_rating = \"\"\n",
        "        if star_tag:\n",
        "            classes = star_tag.get(\"class\", [])\n",
        "\n",
        "            for c in classes:\n",
        "                if c.lower() not in (\"star-rating\",):\n",
        "                    star_rating = c\n",
        "                    break\n",
        "\n",
        "        books.append({\n",
        "            \"Title\": title,\n",
        "            \"Price\": price,\n",
        "            \"Availability\": availability,\n",
        "            \"Star Rating\": star_rating\n",
        "        })\n",
        "\n",
        "\n",
        "    next_li = soup.select_one(\"li.next a\")\n",
        "    if next_li:\n",
        "        next_href = next_li.get(\"href\")\n",
        "\n",
        "        url = requests.compat.urljoin(url, next_href)\n",
        "        time.sleep(1)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "\n",
        "df = pd.DataFrame(books)\n",
        "df.to_csv(\"books.csv\", index=False, encoding=\"utf-8\")\n",
        "print(\"Saved\", len(df), \"books to books.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install requests beautifulsoup4 pandas lxml selenium webdriver-manager\n",
        "\n",
        "!apt-get update -y\n",
        "!apt-get install -y chromium-browser chromium-chromedriver\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aQ9c2h_UGBPW",
        "outputId": "72c5cc97-3001-4259-d125-96f63d5e2128"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (5.4.0)\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.12/dist-packages (4.35.0)\n",
            "Requirement already satisfied: webdriver-manager in /usr/local/lib/python3.12/dist-packages (4.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.14.1)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: trio~=0.30.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (0.30.0)\n",
            "Requirement already satisfied: trio-websocket~=0.12.2 in /usr/local/lib/python3.12/dist-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from webdriver-manager) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from webdriver-manager) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.12/dist-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n",
            "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://cli.github.com/packages stable InRelease\n",
            "Hit:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:6 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:11 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "chromium-browser is already the newest version (1:85.0.4183.83-0ubuntu2.22.04.1).\n",
            "chromium-chromedriver is already the newest version (1:85.0.4183.83-0ubuntu2.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update -y\n",
        "!apt-get install -y wget unzip\n",
        "!wget -q https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "!apt-get install -y ./google-chrome-stable_current_amd64.deb\n",
        "\n",
        "!pip install selenium webdriver-manager\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cIfWff-DHW20",
        "outputId": "7e6f703e-c432-49d1-f9dc-10c27ac1324b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://cli.github.com/packages stable InRelease\n",
            "Hit:3 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:5 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:6 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:8 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-26ubuntu3.2).\n",
            "wget is already the newest version (1.21.2-2ubuntu1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'google-chrome-stable' instead of './google-chrome-stable_current_amd64.deb'\n",
            "The following additional packages will be installed:\n",
            "  libvulkan1 mesa-vulkan-drivers\n",
            "The following NEW packages will be installed:\n",
            "  google-chrome-stable libvulkan1 mesa-vulkan-drivers\n",
            "0 upgraded, 3 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 10.9 MB/131 MB of archives.\n",
            "After this operation, 447 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libvulkan1 amd64 1.3.204.1-2 [128 kB]\n",
            "Get:2 /content/google-chrome-stable_current_amd64.deb google-chrome-stable amd64 140.0.7339.80-1 [121 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 mesa-vulkan-drivers amd64 23.2.1-1ubuntu3.1~22.04.3 [10.7 MB]\n",
            "Fetched 10.9 MB in 2s (4,477 kB/s)\n",
            "Selecting previously unselected package libvulkan1:amd64.\n",
            "(Reading database ... 126829 files and directories currently installed.)\n",
            "Preparing to unpack .../libvulkan1_1.3.204.1-2_amd64.deb ...\n",
            "Unpacking libvulkan1:amd64 (1.3.204.1-2) ...\n",
            "Selecting previously unselected package google-chrome-stable.\n",
            "Preparing to unpack .../google-chrome-stable_current_amd64.deb ...\n",
            "Unpacking google-chrome-stable (140.0.7339.80-1) ...\n",
            "Selecting previously unselected package mesa-vulkan-drivers:amd64.\n",
            "Preparing to unpack .../mesa-vulkan-drivers_23.2.1-1ubuntu3.1~22.04.3_amd64.deb ...\n",
            "Unpacking mesa-vulkan-drivers:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Setting up libvulkan1:amd64 (1.3.204.1-2) ...\n",
            "Setting up mesa-vulkan-drivers:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Setting up google-chrome-stable (140.0.7339.80-1) ...\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/google-chrome (google-chrome) in auto mode\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.12/dist-packages (4.35.0)\n",
            "Requirement already satisfied: webdriver-manager in /usr/local/lib/python3.12/dist-packages (4.0.2)\n",
            "Requirement already satisfied: urllib3<3.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
            "Requirement already satisfied: trio~=0.30.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (0.30.0)\n",
            "Requirement already satisfied: trio-websocket~=0.12.2 in /usr/local/lib/python3.12/dist-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2025.6.15 in /usr/local/lib/python3.12/dist-packages (from selenium) (2025.8.3)\n",
            "Requirement already satisfied: typing_extensions~=4.14.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (4.14.1)\n",
            "Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from webdriver-manager) (2.32.4)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from webdriver-manager) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from webdriver-manager) (25.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (3.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.12/dist-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->webdriver-manager) (3.4.3)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--headless\")\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
        "\n",
        "url = \"https://www.imdb.com/chart/top/\"\n",
        "driver.get(url)\n",
        "time.sleep(2)\n",
        "\n",
        "rows = driver.find_elements(By.CSS_SELECTOR, \"table.chart.full-width tbody tr\")\n",
        "\n",
        "movies = []\n",
        "for row in rows:\n",
        "    title_col = row.find_element(By.CSS_SELECTOR, \"td.titleColumn\")\n",
        "    rank = int(title_col.text.split('.')[0].strip())\n",
        "    title = title_col.find_element(By.TAG_NAME, \"a\").text.strip()\n",
        "    year = title_col.find_element(By.CLASS_NAME, \"secondaryInfo\").text.strip(\"() \")\n",
        "    rating = row.find_element(By.CSS_SELECTOR, \"td.ratingColumn.imdbRating strong\").text.strip()\n",
        "\n",
        "    movies.append({\n",
        "        \"Rank\": rank,\n",
        "        \"Movie Title\": title,\n",
        "        \"Year of Release\": year,\n",
        "        \"IMDB Rating\": rating\n",
        "    })\n",
        "\n",
        "df_imdb = pd.DataFrame(movies)\n",
        "df_imdb.to_csv(\"imdb_top250.csv\", index=False, encoding=\"utf-8\")\n",
        "print(\"saved to imdb_top250.csv\")\n",
        "\n",
        "driver.quit()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Rb7z3lZHIII",
        "outputId": "ffd31bdb-fc07-4224-94eb-72a4ef16fe04"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved to imdb_top250.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "from urllib.parse import urljoin\n",
        "\n",
        "BASE = \"https://www.timeanddate.com/weather/\"\n",
        "\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
        "}\n",
        "\n",
        "resp = requests.get(BASE, headers=headers, timeout=15)\n",
        "resp.raise_for_status()\n",
        "soup = BeautifulSoup(resp.text, \"lxml\")\n",
        "\n",
        "cities = []\n",
        "\n",
        "\n",
        "tables = soup.select(\"table.zebra, table.tb-wt, table.table--left\")\n",
        "\n",
        "rows = []\n",
        "for t in tables:\n",
        "    rows.extend(t.select(\"tbody tr\"))\n",
        "\n",
        "\n",
        "if not rows:\n",
        "\n",
        "    anchors = [a for a in soup.select(\"a\") if a.get(\"href\", \"\").startswith(\"/weather/\")]\n",
        "\n",
        "    anchors = [a for a in anchors if len(a.text.strip()) > 0 and len(a.text.strip()) < 40]\n",
        "\n",
        "    for a in anchors:\n",
        "        parent = a.parent\n",
        "\n",
        "        temp = None\n",
        "        cond = None\n",
        "\n",
        "        for sibling in parent.find_all(string=True, recursive=False):\n",
        "            s = sibling.strip()\n",
        "            if s and (\"°C\" in s or \"°F\" in s):\n",
        "                temp = s\n",
        "                break\n",
        "\n",
        "        img = parent.find(\"img\")\n",
        "        if img and img.get(\"alt\"):\n",
        "            cond = img.get(\"alt\").strip()\n",
        "        rows.append((a, temp, cond))\n",
        "else:\n",
        "\n",
        "    for tr in rows:\n",
        "\n",
        "        a = tr.find(\"a\")\n",
        "        if not a:\n",
        "            continue\n",
        "        city_name = a.text.strip()\n",
        "\n",
        "        temp = \"\"\n",
        "        cond = \"\"\n",
        "\n",
        "        temp_td = tr.find(\"td\", class_=\"r\") or tr.find_all(\"td\")[-1] if tr.find_all(\"td\") else None\n",
        "        if temp_td:\n",
        "            temp = temp_td.text.strip()\n",
        "\n",
        "        img = tr.find(\"img\")\n",
        "        if img and img.get(\"alt\"):\n",
        "            cond = img.get(\"alt\").strip()\n",
        "\n",
        "        cities.append({\n",
        "            \"City Name\": city_name,\n",
        "            \"Temperature\": temp,\n",
        "            \"Weather Condition\": cond\n",
        "        })\n",
        "\n",
        "\n",
        "if rows and isinstance(rows[0], tuple):\n",
        "    cities = []\n",
        "    for a, temp, cond in rows:\n",
        "        cities.append({\n",
        "            \"City Name\": a.text.strip(),\n",
        "            \"Temperature\": temp or \"\",\n",
        "            \"Weather Condition\": cond or \"\"\n",
        "        })\n",
        "\n",
        "\n",
        "if not cities:\n",
        "    print(\"No city data parsed. Page layout may differ. Try inspecting the page or run with network available.\")\n",
        "else:\n",
        "    df = pd.DataFrame(cities)\n",
        "    df.to_csv(\"weather.csv\", index=False, encoding=\"utf-8\")\n",
        "    print(\"Saved\", len(df), \"cities to weather.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzmDnySHGGKu",
        "outputId": "72c471ba-fa8a-4919-84e2-2fbc6a085c7c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 158 cities to weather.csv\n"
          ]
        }
      ]
    }
  ]
}