{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"USA_Housing.csv\")\n",
        "\n",
        "# Split into input features and output variable\n",
        "X = data.drop(\"Price\", axis=1).values\n",
        "y = data[\"Price\"].values\n",
        "\n",
        "# Scale karengee input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Function to calculate beta using Least Squares\n",
        "def least_squares_beta(X_train, y_train):\n",
        "    # Beta = (X^T * X)^-1 * X^T * y\n",
        "    return np.linalg.inv(X_train.T @ X_train) @ X_train.T @ y_train\n",
        "\n",
        "# 5 fold cross validation\n",
        "k = 5\n",
        "n = X_scaled.shape[0]\n",
        "fold_size = n // k\n",
        "r2_scores = []\n",
        "betas = []\n",
        "\n",
        "for i in range(k):\n",
        "    start = i * fold_size\n",
        "    end = start + fold_size if i != k-1 else n\n",
        "\n",
        "    X_test = X_scaled[start:end]\n",
        "    y_test = y[start:end]\n",
        "\n",
        "    X_train = np.concatenate((X_scaled[:start], X_scaled[end:]), axis=0)\n",
        "    y_train = np.concatenate((y[:start], y[end:]), axis=0)\n",
        "\n",
        "    beta = least_squares_beta(X_train, y_train)\n",
        "    y_pred = X_test @ beta\n",
        "    score = r2_score(y_test, y_pred)\n",
        "\n",
        "    betas.append(beta)\n",
        "    r2_scores.append(score)\n",
        "\n",
        "# best beta on maximum R2 score\n",
        "best_index = np.argmax(r2_scores)\n",
        "best_beta = betas[best_index]\n",
        "print(\"R2 Scores for each fold:\", r2_scores)\n",
        "print(\"Best Beta matrix:\", best_beta)\n",
        "\n",
        "# Train on 70% of data using best beta\n",
        "X_train_final, X_test_final, y_train_final, y_test_final = train_test_split(\n",
        "    X_scaled, y, test_size=0.3, random_state=42\n",
        ")\n",
        "# Predicted values using best beta\n",
        "y_pred_final = X_test_final @ best_beta\n",
        "r2_final = r2_score(y_test_final, y_pred_final)\n",
        "print(\"R2 Score on 30% test data:\", r2_final)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ur_BLuQjM7YN",
        "outputId": "a0a412c5-54de-46d1-ea67-61dbe5d9775d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 Scores for each fold: [-11.566262890130577, -10.327833022754156, -12.218871237545434, -10.951296474620897, -11.593510618998712]\n",
            "Best Beta matrix: [231008.84527364 174703.35249181 121834.54293259  -2872.53491108\n",
            " 152806.89864888]\n",
            "R2 Score on 30% test data: -11.983806002911246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Load karo dataset\n",
        "data = pd.read_csv(\"USA_Housing.csv\")\n",
        "\n",
        "# Split into input features/  output variable\n",
        "X = data.drop(\"Price\", axis=1).values\n",
        "y = data[\"Price\"].values.reshape(-1, 1)\n",
        "\n",
        "# Scale input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Add bias term to X\n",
        "X_scaled = np.hstack((np.ones((X_scaled.shape[0], 1)), X_scaled))\n",
        "\n",
        "# Split data: 56% train 14 validation 30 test\n",
        "n = X_scaled.shape[0]\n",
        "train_end = int(0.56 * n)\n",
        "val_end = int(0.70 * n)\n",
        "\n",
        "X_train, y_train = X_scaled[:train_end], y[:train_end]\n",
        "X_val, y_val = X_scaled[train_end:val_end], y[train_end:val_end]\n",
        "X_test, y_test = X_scaled[val_end:], y[val_end:]\n",
        "\n",
        "# Gradient Descent\n",
        "def gradient_descent(X, y, lr, iterations):\n",
        "    m, n = X.shape\n",
        "    beta = np.zeros((n, 1))\n",
        "    for i in range(iterations):\n",
        "        gradients = (1/m) * X.T @ (X @ beta - y)\n",
        "        beta = beta - lr * gradients\n",
        "    return beta\n",
        "\n",
        "# Learning rates to test\n",
        "learning_rates = [0.001, 0.01, 0.1, 1]\n",
        "iterations = 1000\n",
        "\n",
        "best_beta = None\n",
        "best_r2 = -np.inf\n",
        "\n",
        "# Train for learning rate and check validation R2\n",
        "for lr in learning_rates:\n",
        "    beta = gradient_descent(X_train, y_train, lr, iterations)\n",
        "    y_val_pred = X_val @ beta\n",
        "    r2 = r2_score(y_val, y_val_pred)\n",
        "    print(f\"Learning Rate: {lr}, Validation R2: {r2}\")\n",
        "    if r2 > best_r2:\n",
        "        best_r2 = r2\n",
        "        best_beta = beta\n",
        "\n",
        "# Evaluate best beta on test set\n",
        "y_test_pred = X_test @ best_beta\n",
        "r2_test = r2_score(y_test, y_test_pred)\n",
        "print(\"Best Beta coefficients:\\n\", best_beta)\n",
        "print(\"R2 Score on Test Set:\", r2_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEr8M3WfNaCo",
        "outputId": "8ac09445-15f1-4c9a-b3b6-973163814c9f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning Rate: 0.001, Validation R2: -0.9353469873109566\n",
            "Learning Rate: 0.01, Validation R2: 0.9150931093041854\n",
            "Learning Rate: 0.1, Validation R2: 0.9151040123364315\n",
            "Learning Rate: 1, Validation R2: 0.9151040123364313\n",
            "Best Beta coefficients:\n",
            " [[ 1.23244775e+06]\n",
            " [ 2.31682635e+05]\n",
            " [ 1.63635272e+05]\n",
            " [ 1.19025219e+05]\n",
            " [-2.74956842e+02]\n",
            " [ 1.50705906e+05]]\n",
            "R2 Score on Test Set: 0.917477081644098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mgKiYp_M4nq",
        "outputId": "498d94d6-c681-4c23-e5f2-e9ba033b8e46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 Score without PCA: 0.7962231220908701\n",
            "R2 Score with PCA: 0.751700022926359\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Load dataset with column names\n",
        "columns = [\"symboling\", \"normalized_losses\", \"make\", \"fuel_type\", \"aspiration\",\"num_doors\",\n",
        "           \"body_style\", \"drive_wheels\", \"engine_location\", \"wheel_base\", \"length\", \"width\",\n",
        "           \"height\", \"curb_weight\", \"engine_type\", \"num_cylinders\", \"engine_size\", \"fuel_system\",\n",
        "           \"bore\", \"stroke\", \"compression_ratio\", \"horsepower\", \"peak_rpm\", \"city_mpg\",\n",
        "           \"highway_mpg\", \"price\"]\n",
        "\n",
        "data = pd.read_csv(\"imports-85.data.txt\", names=columns, na_values=\"?\")\n",
        "\n",
        "# Central tendency\n",
        "for col in data.columns:\n",
        "    if data[col].dtype == \"object\":\n",
        "        data[col] = data[col].fillna(data[col].mode()[0])\n",
        "    else:\n",
        "        data[col] = data[col].fillna(data[col].median())\n",
        "\n",
        "# Drop rows with NaN in price\n",
        "data = data.dropna(subset=['price'])\n",
        "data['price'] = data['price'].astype(float)\n",
        "\n",
        "# Convert word numbers to numeric\n",
        "num_map = {\"two\": 2, \"three\": 3, \"four\": 4, \"five\": 5, \"six\": 6, \"eight\": 8, \"twelve\": 12}\n",
        "data['num_doors'] = data['num_doors'].map(num_map)\n",
        "data['num_cylinders'] = data['num_cylinders'].map(num_map)\n",
        "\n",
        "# Dummy encoding for body_style and drive_wheels\n",
        "data = pd.get_dummies(data, columns=['body_style', 'drive_wheels'], drop_first=True)\n",
        "\n",
        "# Label encoding for make, aspiration, engine_location, fuel_type\n",
        "le = LabelEncoder()\n",
        "for col in ['make', 'aspiration', 'engine_location', 'fuel_type']:\n",
        "    data[col] = le.fit_transform(data[col])\n",
        "\n",
        "# Custom encoding for fuel_system and engine_type\n",
        "data['fuel_system'] = data['fuel_system'].apply(lambda x: 1 if 'pfi' in x.lower() else 0)\n",
        "data['engine_type'] = data['engine_type'].apply(lambda x: 1 if 'ohc' in x.lower() else 0)\n",
        "\n",
        "# Split karo features and target\n",
        "X = data.drop('price', axis=1).values\n",
        "y = data['price'].values\n",
        "\n",
        "# Scalingggg the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split 70% train/ 30% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Linear Regression mein train\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred = lr.predict(X_test)\n",
        "print(\"R2 Score without PCA:\", r2_score(y_test, y_pred))\n",
        "\n",
        "# Apply karna hai PCA dimensionality reduction\n",
        "pca = PCA(n_components=0.95)  # preserve 95% variance\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "\n",
        "# Train Linear Regression on reduced features\n",
        "lr_pca = LinearRegression()\n",
        "lr_pca.fit(X_train_pca, y_train)\n",
        "y_pred_pca = lr_pca.predict(X_test_pca)\n",
        "print(\"R2 Score with PCA:\", r2_score(y_test, y_pred_pca))\n"
      ]
    }
  ]
}